{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8652019,"sourceType":"datasetVersion","datasetId":5182578}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"_______________________","metadata":{}},{"cell_type":"markdown","source":"# **About The Model**","metadata":{}},{"cell_type":"markdown","source":"This project focuses on developing a classification model to predict health risk levels based on key health indicators: Age, BMI, Alcohol Consumption, Physical Activity, and Liver Function Test results. By analyzing these features, the model aims to predict the probability of an individual to develop liver diseases, providing valuable insights into how lifestyle factors and demographics influence overall health. This model can be a useful tool for preventive healthcare, helping to identify individuals who may be at higher risk for health issues.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align: left;\">\n\n<h2>Feature Descriptions</h2>\n\n<table style=\"width:100%; border-collapse: collapse; text-align:left; table-layout: auto;\">\n  <tr>\n    <th style=\"border: 1px solid black; padding: 8px; background-color: #f2f2f2; width: 30%;\"><strong>Feature</strong></th>\n    <th style=\"border: 1px solid black; padding: 8px; background-color: #f2f2f2; width: 70%;\"><strong>Description</strong></th>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">Age</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">The age of the individual.</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">Gender</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">The gender of the individual (binary variable: 0 for male, 1 for female).</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">BMI</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Body Mass Index, a measure of body fat based on height and weight.</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">AlcoholConsumption</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Amount of alcohol consumed.</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">Smoking</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Whether the individual smokes (binary variable: 0 for non-smoker, 1 for smoker).</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">GeneticRisk</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Genetic predisposition to liver disease (binary variable: 0 for low risk, 1 for high risk).</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">PhysicalActivity</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Level of physical activity.</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">Diabetes</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Whether the individual has diabetes (binary variable: 0 for no, 1 for yes).</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">Hypertension</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Whether the individual has hypertension (binary variable: 0 for no, 1 for yes).</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">LiverFunctionTest</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">A measure of liver function.</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">Diagnosis</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Target variable indicating whether the individual is diagnosed with liver disease (binary variable: 0 for no, 1 for yes).</td>\n  </tr>\n</table>\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"# **Importing Libraries**","metadata":{}},{"cell_type":"code","source":"# For Manipulation and Visualasation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# Machine Learning Libraries\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\nimport warnings # To remove warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:29:58.786706Z","iopub.execute_input":"2024-08-20T23:29:58.787145Z","iopub.status.idle":"2024-08-20T23:29:59.859990Z","shell.execute_reply.started":"2024-08-20T23:29:58.787104Z","shell.execute_reply":"2024-08-20T23:29:59.858913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Importing Dataset**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/predict-liver-disease-1700-records-dataset/Liver_disease_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:29:59.866058Z","iopub.execute_input":"2024-08-20T23:29:59.866459Z","iopub.status.idle":"2024-08-20T23:29:59.884004Z","shell.execute_reply.started":"2024-08-20T23:29:59.866420Z","shell.execute_reply":"2024-08-20T23:29:59.882797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:29:59.885500Z","iopub.execute_input":"2024-08-20T23:29:59.886644Z","iopub.status.idle":"2024-08-20T23:29:59.907013Z","shell.execute_reply.started":"2024-08-20T23:29:59.886591Z","shell.execute_reply":"2024-08-20T23:29:59.905872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Inspecting The Dataset**","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:29:59.910489Z","iopub.execute_input":"2024-08-20T23:29:59.910859Z","iopub.status.idle":"2024-08-20T23:29:59.925442Z","shell.execute_reply.started":"2024-08-20T23:29:59.910830Z","shell.execute_reply":"2024-08-20T23:29:59.923982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:29:59.926809Z","iopub.execute_input":"2024-08-20T23:29:59.927142Z","iopub.status.idle":"2024-08-20T23:29:59.941963Z","shell.execute_reply.started":"2024-08-20T23:29:59.927113Z","shell.execute_reply":"2024-08-20T23:29:59.940806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Every Column has correct datatype and no duplicate data found","metadata":{}},{"cell_type":"markdown","source":"# **Checking for Null Values**","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:29:59.943390Z","iopub.execute_input":"2024-08-20T23:29:59.943833Z","iopub.status.idle":"2024-08-20T23:29:59.954771Z","shell.execute_reply.started":"2024-08-20T23:29:59.943790Z","shell.execute_reply":"2024-08-20T23:29:59.953539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df.isnull(),yticklabels=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:29:59.956077Z","iopub.execute_input":"2024-08-20T23:29:59.956507Z","iopub.status.idle":"2024-08-20T23:30:00.530957Z","shell.execute_reply.started":"2024-08-20T23:29:59.956469Z","shell.execute_reply":"2024-08-20T23:30:00.529515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No Null Values found in Dataset","metadata":{}},{"cell_type":"markdown","source":"# **Descriptive Statistics**","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:00.532848Z","iopub.execute_input":"2024-08-20T23:30:00.533470Z","iopub.status.idle":"2024-08-20T23:30:00.584146Z","shell.execute_reply.started":"2024-08-20T23:30:00.533410Z","shell.execute_reply":"2024-08-20T23:30:00.582741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **EDA**","metadata":{}},{"cell_type":"markdown","source":"### Checking Distribution","metadata":{}},{"cell_type":"code","source":"# Distribution of Age\nplt.figure(figsize=(8, 4))\nsns.histplot(df['Age'], bins=20, kde=True, color='skyblue')\nplt.title('Distribution of Age')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:00.585409Z","iopub.execute_input":"2024-08-20T23:30:00.585746Z","iopub.status.idle":"2024-08-20T23:30:01.065635Z","shell.execute_reply.started":"2024-08-20T23:30:00.585701Z","shell.execute_reply":"2024-08-20T23:30:01.064274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Median:',df['Age'].median())\nprint('Mean:',df['Age'].mean())\nprint('\\nThe Median is not very different from Mean, the distribution is normal, and no outlier detected, so we can proceed with it.')","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:01.067171Z","iopub.execute_input":"2024-08-20T23:30:01.067509Z","iopub.status.idle":"2024-08-20T23:30:01.076582Z","shell.execute_reply.started":"2024-08-20T23:30:01.067481Z","shell.execute_reply":"2024-08-20T23:30:01.075311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution of Gender\ngender_counts = df['Gender'].value_counts()\n\nplt.figure(figsize=(4, 4))\nplt.pie(gender_counts, labels=gender_counts.index, colors=['skyblue', 'lightcoral'], autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))\nplt.title('Gender Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:01.078206Z","iopub.execute_input":"2024-08-20T23:30:01.078589Z","iopub.status.idle":"2024-08-20T23:30:01.221939Z","shell.execute_reply.started":"2024-08-20T23:30:01.078557Z","shell.execute_reply":"2024-08-20T23:30:01.220182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution of BMI\nplt.figure(figsize=(8, 4))\nsns.histplot(df['BMI'], bins=20, kde=True, color='skyblue')\nplt.title('Distribution of BMI')\nplt.xlabel('BMI')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:01.224020Z","iopub.execute_input":"2024-08-20T23:30:01.224891Z","iopub.status.idle":"2024-08-20T23:30:01.651091Z","shell.execute_reply.started":"2024-08-20T23:30:01.224829Z","shell.execute_reply":"2024-08-20T23:30:01.649812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Median:',df['BMI'].median())\nprint('Mean:',df['BMI'].mean())\nprint('\\nThe Median is not very different from Mean, the distribution is normal, and no outlier detected, so we can proceed with it.')","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:01.655967Z","iopub.execute_input":"2024-08-20T23:30:01.656377Z","iopub.status.idle":"2024-08-20T23:30:01.664569Z","shell.execute_reply.started":"2024-08-20T23:30:01.656334Z","shell.execute_reply":"2024-08-20T23:30:01.663137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of AlcoholConsumption\nplt.figure(figsize=(8, 4))\nsns.histplot(df['AlcoholConsumption'], bins=20, kde=True, color='skyblue')\nplt.title('Distribution of AlcoholConsumption')\nplt.xlabel('AlcoholConsumption')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:01.666185Z","iopub.execute_input":"2024-08-20T23:30:01.666644Z","iopub.status.idle":"2024-08-20T23:30:02.088310Z","shell.execute_reply.started":"2024-08-20T23:30:01.666612Z","shell.execute_reply":"2024-08-20T23:30:02.087147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Median:',df['AlcoholConsumption'].median())\nprint('Mean:',df['AlcoholConsumption'].mean())\nprint('\\nThe Median is not very different from Mean, the distribution is normal, and no outlier detected, so we can proceed with it.')","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:02.089683Z","iopub.execute_input":"2024-08-20T23:30:02.090029Z","iopub.status.idle":"2024-08-20T23:30:02.097571Z","shell.execute_reply.started":"2024-08-20T23:30:02.090000Z","shell.execute_reply":"2024-08-20T23:30:02.096427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of Smoking\nsmoking_counts = df['Smoking'].value_counts()\n\nplt.figure(figsize=(4, 4))\nplt.pie(smoking_counts, labels=smoking_counts.index, colors=['skyblue', 'lightcoral'], autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))\nplt.title('Smoking Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:02.098964Z","iopub.execute_input":"2024-08-20T23:30:02.099383Z","iopub.status.idle":"2024-08-20T23:30:02.228260Z","shell.execute_reply.started":"2024-08-20T23:30:02.099346Z","shell.execute_reply":"2024-08-20T23:30:02.226912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of Genetic Risk\ngenetic_counts = df['GeneticRisk'].value_counts()\n\nplt.figure(figsize=(4, 4))\nplt.pie(genetic_counts, labels=genetic_counts.index, colors=['skyblue', 'lightcoral'], autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))\nplt.title('GeneticRisk Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:02.229659Z","iopub.execute_input":"2024-08-20T23:30:02.230433Z","iopub.status.idle":"2024-08-20T23:30:02.418239Z","shell.execute_reply.started":"2024-08-20T23:30:02.230308Z","shell.execute_reply":"2024-08-20T23:30:02.416634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of PhysicalActivity\n\nplt.figure(figsize=(8, 4))\nsns.histplot(df['PhysicalActivity'], bins=20, kde=True, color='skyblue')\nplt.title('Distribution of PhysicalActivity')\nplt.xlabel('PhysicalActivity')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:02.420312Z","iopub.execute_input":"2024-08-20T23:30:02.421160Z","iopub.status.idle":"2024-08-20T23:30:02.839122Z","shell.execute_reply.started":"2024-08-20T23:30:02.421105Z","shell.execute_reply":"2024-08-20T23:30:02.837810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Median:',df['PhysicalActivity'].median())\nprint('Mean:',df['PhysicalActivity'].mean())\nprint('\\nThe Median is not very different from Mean, the distribution is normal, and no outlier detected, so we can proceed with it.')","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:02.840773Z","iopub.execute_input":"2024-08-20T23:30:02.841234Z","iopub.status.idle":"2024-08-20T23:30:02.849783Z","shell.execute_reply.started":"2024-08-20T23:30:02.841192Z","shell.execute_reply":"2024-08-20T23:30:02.848579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of Diabetes\ngenetic_counts = df['Diabetes'].value_counts()\n\nplt.figure(figsize=(4, 4))\nplt.pie(genetic_counts, labels=genetic_counts.index, colors=['skyblue', 'lightcoral'], autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))\nplt.title('Diabetes Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:02.851710Z","iopub.execute_input":"2024-08-20T23:30:02.852174Z","iopub.status.idle":"2024-08-20T23:30:02.993933Z","shell.execute_reply.started":"2024-08-20T23:30:02.852133Z","shell.execute_reply":"2024-08-20T23:30:02.992663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of Hypertension\ngenetic_counts = df['Hypertension'].value_counts()\n\nplt.figure(figsize=(4, 4))\nplt.pie(genetic_counts, labels=genetic_counts.index, colors=['skyblue', 'lightcoral'], autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))\nplt.title('Hypertension Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:02.995631Z","iopub.execute_input":"2024-08-20T23:30:02.996509Z","iopub.status.idle":"2024-08-20T23:30:03.184333Z","shell.execute_reply.started":"2024-08-20T23:30:02.996462Z","shell.execute_reply":"2024-08-20T23:30:03.183129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of LiverFunctionTest\n\nplt.figure(figsize=(8, 4))\nsns.histplot(df['LiverFunctionTest'], bins=20, kde=True, color='skyblue')\nplt.title('Distribution of LiverFunctionTest')\nplt.xlabel('LiverFunctionTest')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:03.185924Z","iopub.execute_input":"2024-08-20T23:30:03.186747Z","iopub.status.idle":"2024-08-20T23:30:03.657671Z","shell.execute_reply.started":"2024-08-20T23:30:03.186680Z","shell.execute_reply":"2024-08-20T23:30:03.656439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Median:',df['LiverFunctionTest'].median())\nprint('Mean:',df['LiverFunctionTest'].mean())\nprint('\\nThe Median is not very different from Mean, the distribution is normal, and no outlier detected, so we can proceed with it.')","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:03.658947Z","iopub.execute_input":"2024-08-20T23:30:03.659273Z","iopub.status.idle":"2024-08-20T23:30:03.666972Z","shell.execute_reply.started":"2024-08-20T23:30:03.659246Z","shell.execute_reply":"2024-08-20T23:30:03.665654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of Diagnosis\ngenetic_counts = df['Diagnosis'].value_counts()\n\nplt.figure(figsize=(4, 4))\nplt.pie(genetic_counts, labels=genetic_counts.index, colors=['skyblue', 'lightcoral'], autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))\nplt.title('Diagnosis Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:03.668578Z","iopub.execute_input":"2024-08-20T23:30:03.669026Z","iopub.status.idle":"2024-08-20T23:30:03.798813Z","shell.execute_reply.started":"2024-08-20T23:30:03.668986Z","shell.execute_reply":"2024-08-20T23:30:03.797645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Distribution of each feature looks great, proceeding for multivariate analysis for Determining which model to use","metadata":{}},{"cell_type":"markdown","source":"# Multivariate Analysis","metadata":{}},{"cell_type":"code","source":"# Pair plot of all columns based on the different categories in the Diagnosis column.\nsns.pairplot(df, hue='Diagnosis', palette='Set2', diag_kind='kde')\nplt.suptitle('Pair Plot', y=1.02)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:03.800426Z","iopub.execute_input":"2024-08-20T23:30:03.801370Z","iopub.status.idle":"2024-08-20T23:30:52.215955Z","shell.execute_reply.started":"2024-08-20T23:30:03.801320Z","shell.execute_reply":"2024-08-20T23:30:52.214629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note: Open the image in New Tab for better visualization & understanding!!**","metadata":{}},{"cell_type":"markdown","source":"**Observation:**\n\nIntense overlapping of Data Points is observered, so Logistic Regression & KNN will not be the best choice for this classification, but we will use them just for representation.","metadata":{}},{"cell_type":"markdown","source":"<table style=\"float: left; border-collapse: collapse; width: auto;\">\n    <thead>\n        <tr>\n            <th style=\"text-align: left; border: 1px solid #ddd; padding: 8px; width: 1%;\"><strong>Model</strong></th>\n            <th style=\"text-align: left; border: 1px solid #ddd; padding: 8px;\"><strong>What to use/What to not use</strong></th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td style=\"border: 1px solid #ddd; padding: 8px; white-space: nowrap;\">Logistic Regression</td>\n            <td style=\"border: 1px solid #ddd; padding: 8px;\">Can be used, but struggles with intense overlap as it finds linear decision boundaries. Errors may be high due to misclassification in overlapping regions.</td>\n        </tr>\n        <tr>\n            <td style=\"border: 1px solid #ddd; padding: 8px; white-space: nowrap;\">K-Nearest Neighbors (KNN)</td>\n            <td style=\"border: 1px solid #ddd; padding: 8px;\">Can be used, handles overlap by considering the local neighborhood of points, but performance decreases with intense overlap, especially if k is not chosen carefully.</td>\n        </tr>\n        <tr>\n            <td style=\"border: 1px solid #ddd; padding: 8px; white-space: nowrap;\">Decision Trees</td>\n            <td style=\"border: 1px solid #ddd; padding: 8px;\">Can be used, creates complex decision boundaries, but may overfit with intense overlap, requiring careful pruning or tuning.</td>\n        </tr>\n        <tr>\n            <td style=\"border: 1px solid #ddd; padding: 8px; white-space: nowrap;\">Random Forest</td>\n            <td style=\"border: 1px solid #ddd; padding: 8px;\">Can be used, reduces overfitting by averaging multiple decision trees, making it more robust with overlap, but still requires careful tuning to balance variance and bias.</td>\n        </tr>\n        <tr>\n            <td style=\"border: 1px solid #ddd; padding: 8px; white-space: nowrap;\">Gradient Boosting Machines (GBM)</td>\n            <td style=\"border: 1px solid #ddd; padding: 8px;\">Can be used, focuses on difficult cases iteratively, creating nuanced decision boundaries that handle overlap well. Requires tuning to avoid overfitting.</td>\n        </tr>\n        <tr>\n            <td style=\"border: 1px solid #ddd; padding: 8px; white-space: nowrap;\">XGBoost</td>\n            <td style=\"border: 1px solid #ddd; padding: 8px;\">Can be used, handles overlap effectively with regularization and iterative improvements. Generally performs well in a variety of overlapping scenarios.</td>\n        </tr>\n        <tr>\n            <td style=\"border: 1px solid #ddd; padding: 8px; white-space: nowrap;\">LightGBM</td>\n            <td style=\"border: 1px solid #ddd; padding: 8px;\">Can be used, efficient and scalable, handles large datasets and complex distributions well. Performs well with overlap, especially in large datasets.</td>\n        </tr>\n        <tr>\n            <td style=\"border: 1px solid #ddd; padding: 8px; white-space: nowrap;\">CatBoost</td>\n            <td style=\"border: 1px solid #ddd; padding: 8px;\">Can be used, effective in handling categorical variables and robust in overlapping data scenarios. Performs particularly well with categorical features and requires less tuning.</td>\n        </tr>\n        <tr>\n            <td style=\"border: 1px solid #ddd; padding: 8px; white-space: nowrap;\">Support Vector Classifier (SVC)</td>\n            <td style=\"border: 1px solid #ddd; padding: 8px;\">Can be used, especially with kernels (like RBF) to handle non-linear overlap, but can be computationally expensive, especially with large datasets.</td>\n        </tr>\n        <tr>\n            <td style=\"border: 1px solid #ddd; padding: 8px; white-space: nowrap;\">Naive Bayes</td>\n            <td style=\"border: 1px solid #ddd; padding: 8px;\">Not recommended with intense overlap, as its independence assumption often fails, leading to poor performance in overlapping scenarios.</td>\n        </tr>\n    </tbody>\n</table>","metadata":{}},{"cell_type":"markdown","source":"# Check for Outliers","metadata":{}},{"cell_type":"code","source":"# Visualizaing the Data points on Box plot to check for any outlier\ndef boxplot_with_points(df, columns):\n    for column in columns:\n        plt.figure(figsize=(8, 4))\n        sns.boxplot(x=df[column], showfliers=False)  # Do not show fliers initially\n        sns.stripplot(x=df[column], color='red', alpha=0.5)  # Overlay data points\n        plt.title(f'Boxplot with Data Points for {column}')\n        plt.show()\n\n# List of columns to check\ncolumns_for_outlier_check = ['Age', 'BMI', 'AlcoholConsumption', 'PhysicalActivity', 'LiverFunctionTest']\n\n# Binary columns are not incluced for outlier check because they are not eligible for it.\n\n# Boxplots with data points\nboxplot_with_points(df, columns_for_outlier_check)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:52.217808Z","iopub.execute_input":"2024-08-20T23:30:52.218226Z","iopub.status.idle":"2024-08-20T23:30:53.876923Z","shell.execute_reply.started":"2024-08-20T23:30:52.218192Z","shell.execute_reply":"2024-08-20T23:30:53.875766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The datapoints are in normal range of whiskers, no outliers detectedn now we can proceed.","metadata":{}},{"cell_type":"markdown","source":"# **Check for Multicolineatiry**","metadata":{}},{"cell_type":"code","source":"#Before proceeding for training, Multicolineraity check is must required.\ncorrelation_matrix = df.corr()\n\nplt.figure(figsize=(8, 5))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1, center=0)\nplt.title('Correlation Heatmap')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:53.878605Z","iopub.execute_input":"2024-08-20T23:30:53.879082Z","iopub.status.idle":"2024-08-20T23:30:54.681932Z","shell.execute_reply.started":"2024-08-20T23:30:53.879040Z","shell.execute_reply":"2024-08-20T23:30:54.680783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Data looks absolutely fine, now we can proceed for model building.","metadata":{}},{"cell_type":"markdown","source":"# **Test Train Split**","metadata":{}},{"cell_type":"code","source":"X = df.drop(\"Diagnosis\", axis=1)\ny = df[\"Diagnosis\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:54.683878Z","iopub.execute_input":"2024-08-20T23:30:54.684394Z","iopub.status.idle":"2024-08-20T23:30:54.691929Z","shell.execute_reply.started":"2024-08-20T23:30:54.684350Z","shell.execute_reply":"2024-08-20T23:30:54.690547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting The Dataset for Training Models\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:54.693226Z","iopub.execute_input":"2024-08-20T23:30:54.693614Z","iopub.status.idle":"2024-08-20T23:30:54.705575Z","shell.execute_reply.started":"2024-08-20T23:30:54.693577Z","shell.execute_reply":"2024-08-20T23:30:54.704199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Implementing Feature Scaling**","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:54.707208Z","iopub.execute_input":"2024-08-20T23:30:54.707812Z","iopub.status.idle":"2024-08-20T23:30:54.722426Z","shell.execute_reply.started":"2024-08-20T23:30:54.707772Z","shell.execute_reply":"2024-08-20T23:30:54.721049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets Import all the models\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n# Importing Metrics\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:54.724049Z","iopub.execute_input":"2024-08-20T23:30:54.725133Z","iopub.status.idle":"2024-08-20T23:30:55.895494Z","shell.execute_reply.started":"2024-08-20T23:30:54.725088Z","shell.execute_reply":"2024-08-20T23:30:55.894474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Building Models**","metadata":{}},{"cell_type":"code","source":"# Defining a dictionary of models\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n    \"Decision Tree\": DecisionTreeClassifier(),\n    \"Random Forest\": RandomForestClassifier(),\n    \"Gradient Boosting\": GradientBoostingClassifier(),\n    \"XGBoost\": XGBClassifier(),\n    \"LightGBM\": LGBMClassifier(),\n    \"CatBoost\": CatBoostClassifier(verbose=0),\n    \"Support Vector Classifier\": SVC(),\n    \"Naive Bayes\": GaussianNB()\n    \n}\n\n# Function to train, evaluate, and print stats for each model\ndef evaluate_models(models, X_train, X_test, y_train, y_test):\n    results = {}\n    for name, model in models.items():\n        print(f\"Training {name}...\")\n        model.fit(X_train, y_train)\n        \n        # Predictions\n        y_pred = model.predict(X_test)\n        \n        # Evaluation metrics\n        accuracy = accuracy_score(y_test, y_pred)\n        report = classification_report(y_test, y_pred)\n        conf_matrix = confusion_matrix(y_test, y_pred)\n        \n        print(f\"{name} Accuracy: {accuracy:.4f}\")\n        print(f\"{name} Classification Report:\\n{report}\")\n        print(f\"{name} Confusion Matrix:\\n{conf_matrix}\")\n        print(\"-\" * 50)\n        \n        results[name] = accuracy\n    \n    # Finding the best model based on accuracy\n    best_model_name = max(results, key=results.get)\n    best_model_accuracy = results[best_model_name]\n    print(f\"Best Model: {best_model_name} with Accuracy: {best_model_accuracy:.4f}\")\n\n# Evaluating all models\nevaluate_models(models, X_train, X_test, y_train, y_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:55.897173Z","iopub.execute_input":"2024-08-20T23:30:55.897925Z","iopub.status.idle":"2024-08-20T23:30:59.182095Z","shell.execute_reply.started":"2024-08-20T23:30:55.897886Z","shell.execute_reply":"2024-08-20T23:30:59.180885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Performance Summary\n\nThis table presents the accuracy of various machine learning models used to predict health risk classification.\n\n<div style=\"text-align: left;\">\n\n## Model Accuracies\n\n<table style=\"width:auto; text-align:left;\">\n  <tr>\n    <th><strong>Model</strong></th>\n    <th><strong>Accuracy</strong></th>\n    <th><strong>Justification</strong></th>\n  </tr>\n  <tr>\n    <td>Logistic Regression</td>\n    <td>0.8088</td>\n    <td>Struggles with dense overlap due to its linear decision boundaries, which are inadequate for distinguishing between overlapping classes. This results in relatively lower accuracy compared to more sophisticated models.</td>\n  </tr>\n    \n   <tr>\n    <td>K-Nearest Neighbors</td>\n    <td>0.7735</td>\n    <td>Performs poorly in intense overlap because it relies on local neighborhoods, which are difficult to define accurately in dense regions. This limitation is evident in its lower accuracy in this case.</td>\n  </tr>\n  \n  <tr>\n    <td>Decision Tree</td>\n    <td>0.8529</td>\n    <td>Handles overlap better than linear models by creating complex, non-linear decision boundaries. It improves performance by capturing intricate data patterns, though it may still overfit to dense areas but performed well in this case.</td>\n  </tr>\n  <tr>\n    <td>Random Forest</td>\n    <td>0.9029</td>\n    <td>Effective in handling dense overlap by averaging multiple decision trees, which helps to generalize better across complex data distributions. It has high accuracy making it one of the best to use in this densly overlapped case.</td>\n  </tr>\n  <tr>\n    <td>Gradient Boosting</td>\n    <td>0.9088</td>\n    <td>Handles overlap well by iteratively focusing on the most challenging cases. Its ability to refine decision boundaries in dense areas leads to improved performance and higher accuracy.</td>\n  </tr>\n  <tr>\n    <td>XGBoost</td>\n    <td>0.8912</td>\n    <td>Effectively manages overlap with regularization and iterative improvements, which helps in refining the decision boundaries and handling complex data distributions, though not as well as Gradient Boosting or Random Forest.</td>\n  </tr>\n  <tr>\n    <td>LightGBM</td>\n    <td>0.8853</td>\n    <td>Scalable and efficient, it manages dense overlaps effectively. However, slightly lower performance compared to XGBoost and Gradient Boosting may be due to its handling of complex data structures and distributions.</td>\n  </tr>\n  <tr>\n    <td><strong>CatBoost</strong></td>\n    <td><strong>0.9147</strong></td>\n    <td><strong>Excels in managing dense overlapping data due to its robust handling of categorical features and effective algorithmic techniques. The highest accuracy reflects its superior capability to handle complex and overlapping data patterns making it the best one to use in this case.</strong></td>\n  </tr>  \n  <tr>\n    <td>Support Vector Classifier</td>\n    <td>0.7735</td>\n    <td>Despite using kernels to handle non-linear boundaries, it struggles with dense overlap due to computational complexity and parameter tuning challenges, resulting in lower accuracy in this scenario.</td>\n  </tr>\n  <tr>\n    <td>Naive Bayes</td>\n    <td>0.8029</td>\n    <td>Assumes feature independence, which is often not valid in overlapping regions. This results in lower performance compared to models that can capture complex relationships between features theefore not suitable for this case.</td>\n  </tr>  \n  \n</table>\n\n## Best Model\n\n- **Best Model:** <strong>CatBoost</strong>\n- **Accuracy:** <strong>0.9147</strong>\n\nThe CatBoost model achieved the highest accuracy of 0.9147, making it the best model for this classification task.\n\n</div>\n","metadata":{}},{"cell_type":"code","source":"# Save the model\nmodels[\"CatBoost\"].save_model('catboost_model.cbm')","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:59.183525Z","iopub.execute_input":"2024-08-20T23:30:59.184008Z","iopub.status.idle":"2024-08-20T23:30:59.204089Z","shell.execute_reply.started":"2024-08-20T23:30:59.183966Z","shell.execute_reply":"2024-08-20T23:30:59.202807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Predicting Liver Health Risk With Example Data**","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\n\n# Load the trained CatBoost model\nmodel = CatBoostClassifier()\nmodel.load_model('catboost_model.cbm')\n\n# Sample data for prediction\nsample_data = {\n    'Age': [45],\n    'Gender': [1],\n    'BMI': [26.5],\n    'AlcoholConsumption': [7],\n    'Smoking': [0],\n    'GeneticRisk': [1],\n    'PhysicalActivity': [4],\n    'Diabetes': [0],\n    'Hypertension': [1],\n    'LiverFunctionTest': [55]\n}\n\n# Convert sample data to DataFrame\ndf_sample = pd.DataFrame(sample_data)\n\n# Predict using the loaded CatBoost model\npredictions = model.predict(df_sample)\npred_proba = model.predict_proba(df_sample)\n\n# Extract probabilities for the class\nprob_disease = pred_proba[0][1] * 100\n\n# Print the result\nprint(f\"Prediction: {'Liver Disease' if predictions[0] == 1 else 'No Liver Disease'}\")\nprint(f\"Prediction Probability: {pred_proba[0]}\")\nprint(f\"Probability of Having Disease: {prob_disease:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T23:30:59.205168Z","iopub.execute_input":"2024-08-20T23:30:59.205509Z","iopub.status.idle":"2024-08-20T23:30:59.225442Z","shell.execute_reply.started":"2024-08-20T23:30:59.205480Z","shell.execute_reply":"2024-08-20T23:30:59.223828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**These Models need further overfitting test and still need to be optimized, you can proceed the further testing and tuning.**","metadata":{}}]}